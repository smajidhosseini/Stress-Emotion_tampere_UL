{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import json,codecs\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,multilabel_confusion_matrix, confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import xlsxwriter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "df = pd.read_csv('em_feat_1020.csv').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18756, 9)\n"
     ]
    }
   ],
   "source": [
    "#separate biosignals from emotion features\n",
    "bio_df = df[['eda_mean', 'eda_min', 'eda_max', 'eda_std', 'eda_kurtosis', 'eda_skew',\n",
    "       'eda_num_peaks', 'eda_amphitude', 'eda_duration', 'hr_mean', 'hr_min',\n",
    "       'hr_max', 'hr_std', 'hr_rms', 'hr_num_peaks', 'hr_amphitude',\n",
    "       'hr_duration', 'temp_mean', 'temp_min', 'temp_max', 'temp_mtd',\n",
    "       'stress', 'user']]\n",
    "emo_df = df[['Angry', 'Disgust', 'Scared', 'Happy', 'Sad',\n",
    "             'Surprised', 'Neutral','stress', 'user']]\n",
    "user_list=df.user.unique()\n",
    "print(emo_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the results into a single excel file\n",
    "filename = 'results_1020_over.xlsx'\n",
    "writer = pd.ExcelWriter(filename,engine='xlsxwriter')\n",
    "\n",
    "pd.DataFrame(user_list,columns=['user_list']).to_excel(writer,sheet_name = \"user_list\", index =False)  \n",
    "writer.save()\n",
    "a = {'metric':[],'user':[],'score':[]}\n",
    "with open(\"confusion.json\", \"w\") as outfile:\n",
    "        json.dump(a, outfile)\n",
    "predfilename = 'pred'+filename[8:12]+'.xlsx'\n",
    "user_list = emo_df.user.unique()\n",
    "with pd.ExcelWriter(predfilename, engine='openpyxl', mode='w') as writer:\n",
    "        pd.DataFrame(user_list).to_excel(writer, sheet_name = 'user_list',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results2excel(metric,rf_score,dt_score,et_score,xgb_score,user_list,sheet_name):\n",
    "    \n",
    "\n",
    "    rf= pd.DataFrame(rf_score)\n",
    "    dt= pd.DataFrame(dt_score)\n",
    "    et= pd.DataFrame(et_score)\n",
    "    xg= pd.DataFrame(xgb_score)\n",
    "    user_list = pd.DataFrame(user_list)\n",
    "\n",
    "    results = pd.DataFrame()\n",
    "    results = pd.concat([user_list,rf,dt,et,xg],axis=1)\n",
    "    results.columns = ['user','random forest','decision tree','extra trees','xgboost']\n",
    "    #with pd.ExcelWriter('results.xlsx',mode='a') as writer:  \n",
    "    #    results.to_excel(writer, sheet_name='sheet_name')  \n",
    "    with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "        results.to_excel(writer, sheet_name = sheet_name+'_'+metric,index=False)\n",
    "\n",
    "        writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mtrx2json(metric,score,user,sheetname):\n",
    "    a = {'metric':[],'user':[],'score':[]}\n",
    "    a['metric'].append(metric)\n",
    "    a['user'].append(user)\n",
    "    a['score'].append(score.tolist())\n",
    "    print(a)\n",
    "    #if (user == 'ST') and (sheetname == 'Pearsons1') and (metric == 'xgb'):\n",
    "    #with open(\"confusion.json\", \"a\") as outfile:\n",
    "    #    json.dump(a, outfile)\n",
    "\n",
    "    #with open(\"confusion.json\", mode='a', encoding='utf-8') as feedsjson:\n",
    "    \n",
    "    json.dump(a, codecs.open('confusion.json', 'a', encoding='utf-8'), \n",
    "          separators=(',', ':'), \n",
    "          sort_keys=True, \n",
    "          indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#machine learning models\n",
    "def machine_learning(dataframe, sheet_name,strategy):\n",
    "\n",
    "    xgb_accuracy, et_accuracy, dt_accuracy, rf_accuracy = [], [], [], []\n",
    "    xgb_precision, et_precision, dt_precision, rf_precision = [], [], [], []\n",
    "    xgb_recall, et_recall, dt_recall, rf_recall = [], [], [], []\n",
    "    xgb_f1score, et_f1score, dt_f1score, rf_f1score = [], [], [], []\n",
    "    user_list = []\n",
    "    rf_conf, et_conf, dt_conf, xgb_conf = [],[],[],[]\n",
    "    for user in dataframe.user.unique():\n",
    "\n",
    "        user_list.append(user)\n",
    "\n",
    "        \n",
    "        train_set = dataframe[dataframe['user'] != user]\n",
    "        over = RandomOverSampler(sampling_strategy=strategy,random_state=42)\n",
    "        #su = SMOTE(random_state=42,sampling_strategy=strategy)\n",
    "        #X_train, y_train = over.fit_resample(train_set.drop(columns= ['user','stress']), train_set['stress'])\n",
    "        #under = RandomUnderSampler(sampling_strategy=strategy)\n",
    "        X_train, y_train = over.fit_resample(train_set.drop(columns= ['user','stress']),train_set['stress'])\n",
    "        \n",
    "        test_set = dataframe[dataframe['user'] == user]\n",
    "        #print(test_set.stress.value_counts())\n",
    "        #print(np.unique(y_train,return_counts = True))\n",
    "        rf = RandomForestClassifier(n_estimators = 100, max_depth=7, min_samples_leaf=5,random_state = 123)\n",
    "        rf.fit(X_train, y_train)\n",
    "        predictions = rf.predict(test_set.drop(columns=['user','stress']))\n",
    "        #print(multilabel_confusion_matrix(predictions,test_set['stress']))\n",
    "        #print(accuracy_score(predictions,test_set['stress']))\n",
    "        #print(np.unique(predictions,return_counts=True))\n",
    "        rf_accuracy.append(accuracy_score(predictions,test_set['stress']))\n",
    "        \n",
    "        rf_precision.append(precision_score(predictions,test_set['stress'],average = 'macro'))\n",
    "        rf_recall.append(recall_score(predictions,test_set['stress'],average = 'macro'))\n",
    "        rf_f1score.append(f1_score(predictions,test_set['stress'],average = 'macro'))\n",
    "        rf_conf = multilabel_confusion_matrix(predictions,test_set['stress'])\n",
    "        print(classification_report(predictions,test_set['stress']))\n",
    "        conf_mtrx2json('rf_conf',rf_conf,user,sheet_name)\n",
    "\n",
    "        et = ExtraTreesClassifier(random_state=123, max_depth=7,min_samples_leaf=5)\n",
    "        et.fit(X_train, y_train)\n",
    "        predictions = et.predict(test_set.drop(columns=['user','stress']))\n",
    "        et_accuracy.append(accuracy_score(predictions,test_set['stress']))\n",
    "        et_precision.append(precision_score(predictions,test_set['stress'],average = 'weighted'))\n",
    "        et_recall.append(recall_score(predictions,test_set['stress'],average = 'weighted'))\n",
    "        et_f1score.append(f1_score(predictions,test_set['stress'],average = 'weighted'))\n",
    "        et_conf = multilabel_confusion_matrix(predictions,test_set['stress'])\n",
    "        #print(classification_report(predictions,test_set['stress']))\n",
    "        conf_mtrx2json('et_conf',et_conf,user,sheet_name)\n",
    "\n",
    "        dt =DecisionTreeClassifier(random_state=123, max_depth=7,min_samples_leaf=5 )\n",
    "        dt.fit(X_train, y_train)\n",
    "        predictions = dt.predict(test_set.drop(columns=['user','stress']))\n",
    "        dt_accuracy.append(accuracy_score(predictions,test_set['stress']))\n",
    "        dt_precision.append(precision_score(predictions,test_set['stress'],average = 'weighted'))\n",
    "        dt_recall.append(recall_score(predictions,test_set['stress'],average = 'weighted'))\n",
    "        dt_f1score.append(f1_score(predictions,test_set['stress'],average = 'weighted'))\n",
    "        dt_conf = multilabel_confusion_matrix(predictions,test_set['stress'])\n",
    "        #print(classification_report(predictions,test_set['stress']))\n",
    "        conf_mtrx2json('dt_conf',dt_conf,user,sheet_name)\n",
    "\n",
    "        xgb = XGBClassifier()\n",
    "        xgb.fit(X_train, y_train)\n",
    "        predictions = xgb.predict(test_set.drop(columns=['user','stress']))\n",
    "        xgb_accuracy.append(accuracy_score(predictions,test_set['stress']))\n",
    "        xgb_precision.append(precision_score(predictions,test_set['stress'],average = 'weighted'))\n",
    "        xgb_recall.append(recall_score(predictions,test_set['stress'],average = 'weighted'))\n",
    "        xgb_f1score.append(f1_score(predictions,test_set['stress'],average = 'weighted'))\n",
    "        xgb_conf = multilabel_confusion_matrix(predictions,test_set['stress'])\n",
    "        #print(classification_report(predictions,test_set['stress']))\n",
    "        conf_mtrx2json('xgb_conf',xgb_conf,user,sheet_name)\n",
    "\n",
    "    results2excel('acc',rf_accuracy,dt_accuracy,et_accuracy,xgb_accuracy,user_list,sheet_name) \n",
    "    results2excel('pre',rf_precision,dt_precision,et_precision,xgb_precision,user_list,sheet_name) \n",
    "    results2excel('rec',rf_recall,dt_recall,et_recall,xgb_recall,user_list,sheet_name)\n",
    "    results2excel('f1score',rf_f1score,dt_f1score,et_f1score,xgb_f1score,user_list,sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA function\n",
    "def Pca(dataset,target):\n",
    "    pcas = PCA(n_components=3)\n",
    "    principalComponents = pcas.fit_transform(dataset)\n",
    "    ppal_df = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2','PC3'])\n",
    "    final_df = pd.concat([ppal_df, target], axis = 1)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D plot function\n",
    "def plot3d(dataset, image_size,title):\n",
    "    fig = plt.figure(figsize=image_size)\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter(dataset['PC1'], dataset['PC2'], dataset['PC3'], c=dataset['stress'])\n",
    "        \n",
    "    # make simple, bare axis lines through space:\n",
    "    \n",
    "    # label the axes\n",
    "    ax.axes.set_xlim3d(left   = dataset['PC1'].min(), right = dataset['PC1'].max())\n",
    "    ax.axes.set_ylim3d(bottom = dataset['PC2'].min(), top   = dataset['PC2'].max())\n",
    "    ax.axes.set_ylim3d(bottom = dataset['PC3'].min(), top   = dataset['PC3'].max())\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    ax.set_zlabel(\"PC3\")\n",
    "    ax.set_title(f\"PCA on the {title} data set\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      1502\n",
      "           1       0.00      0.00      0.00        86\n",
      "           2       0.00      0.01      0.01       110\n",
      "\n",
      "    accuracy                           0.76      1698\n",
      "   macro avg       0.29      0.29      0.29      1698\n",
      "weighted avg       0.77      0.76      0.76      1698\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['HT'], 'score': [[[[1, 195], [211, 1291]], [[1612, 0], [86, 0]], [[1377, 211], [109, 1]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1683\n",
      "           2       0.01      0.13      0.02        15\n",
      "\n",
      "    accuracy                           0.87      1698\n",
      "   macro avg       0.50      0.50      0.47      1698\n",
      "weighted avg       0.98      0.87      0.92      1698\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['HT'], 'score': [[[[2, 13], [210, 1473]], [[1473, 210], [13, 2]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81      1329\n",
      "           1       0.00      0.00      0.00       279\n",
      "           2       0.03      0.08      0.05        90\n",
      "\n",
      "    accuracy                           0.68      1698\n",
      "   macro avg       0.27      0.31      0.29      1698\n",
      "weighted avg       0.60      0.68      0.64      1698\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['HT'], 'score': [[[[24, 345], [188, 1141]], [[1419, 0], [279, 0]], [[1403, 205], [83, 7]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84      1432\n",
      "           1       0.00      0.00      0.00       197\n",
      "           2       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.72      1698\n",
      "   macro avg       0.27      0.28      0.28      1698\n",
      "weighted avg       0.69      0.72      0.71      1698\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['HT'], 'score': [[[[0, 266], [212, 1220]], [[1501, 0], [197, 0]], [[1417, 212], [69, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      1691\n",
      "           1       0.02      0.19      0.03        31\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.64      1727\n",
      "   macro avg       0.33      0.28      0.27      1727\n",
      "weighted avg       0.96      0.64      0.77      1727\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['IT'], 'score': [[[[13, 23], [587, 1104]], [[1340, 356], [25, 6]], [[1484, 238], [5, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79      1720\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.65      1727\n",
      "   macro avg       0.33      0.22      0.26      1727\n",
      "weighted avg       0.99      0.65      0.79      1727\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['IT'], 'score': [[[[3, 4], [597, 1123]], [[1365, 362], [0, 0]], [[1482, 238], [7, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.82      1422\n",
      "           1       0.32      0.46      0.37       252\n",
      "           2       0.03      0.13      0.05        53\n",
      "\n",
      "    accuracy                           0.68      1727\n",
      "   macro avg       0.43      0.44      0.41      1727\n",
      "weighted avg       0.81      0.68      0.73      1727\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['IT'], 'score': [[[[226, 79], [374, 1048]], [[1228, 247], [137, 115]], [[1443, 231], [46, 7]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.67      0.78      1542\n",
      "           1       0.15      0.29      0.20       181\n",
      "           2       0.00      0.25      0.01         4\n",
      "\n",
      "    accuracy                           0.63      1727\n",
      "   macro avg       0.36      0.40      0.33      1727\n",
      "weighted avg       0.84      0.63      0.71      1727\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['IT'], 'score': [[[[93, 92], [507, 1035]], [[1237, 309], [128, 53]], [[1486, 237], [3, 1]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79      1563\n",
      "           1       0.02      0.03      0.03        87\n",
      "           2       0.04      0.26      0.07        62\n",
      "\n",
      "    accuracy                           0.64      1712\n",
      "   macro avg       0.33      0.33      0.29      1712\n",
      "weighted avg       0.86      0.64      0.73      1712\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['JT'], 'score': [[[[80, 69], [494, 1069]], [[1482, 143], [84, 3]], [[1238, 412], [46, 16]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.65      0.76      1608\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.01      0.06      0.02       104\n",
      "\n",
      "    accuracy                           0.61      1712\n",
      "   macro avg       0.31      0.24      0.26      1712\n",
      "weighted avg       0.86      0.61      0.71      1712\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['JT'], 'score': [[[[7, 97], [567, 1041]], [[1566, 146], [0, 0]], [[1186, 422], [98, 6]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75      1249\n",
      "           1       0.34      0.17      0.22       291\n",
      "           2       0.10      0.25      0.14       172\n",
      "\n",
      "    accuracy                           0.58      1712\n",
      "   macro avg       0.41      0.38      0.37      1712\n",
      "weighted avg       0.64      0.58      0.60      1712\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['JT'], 'score': [[[[224, 239], [350, 899]], [[1324, 97], [242, 49]], [[1155, 385], [129, 43]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74      1464\n",
      "           1       0.23      0.18      0.21       184\n",
      "           2       0.02      0.12      0.03        64\n",
      "\n",
      "    accuracy                           0.59      1712\n",
      "   macro avg       0.37      0.32      0.33      1712\n",
      "weighted avg       0.75      0.59      0.66      1712\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['JT'], 'score': [[[[77, 171], [497, 967]], [[1416, 112], [150, 34]], [[1228, 420], [56, 8]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.61      0.73      1588\n",
      "           1       0.03      0.09      0.05       117\n",
      "           2       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.57      1715\n",
      "   macro avg       0.31      0.23      0.26      1715\n",
      "weighted avg       0.84      0.57      0.68      1715\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['KT'], 'score': [[[[21, 106], [623, 965]], [[1298, 300], [107, 10]], [[1371, 334], [10, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77      1709\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.62      1715\n",
      "   macro avg       0.33      0.21      0.26      1715\n",
      "weighted avg       0.99      0.62      0.76      1715\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['KT'], 'score': [[[[2, 4], [642, 1067]], [[1404, 310], [1, 0]], [[1376, 334], [5, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.68      0.51       647\n",
      "           1       0.50      0.23      0.31       693\n",
      "           2       0.41      0.37      0.39       375\n",
      "\n",
      "    accuracy                           0.43      1715\n",
      "   macro avg       0.44      0.42      0.40      1715\n",
      "weighted avg       0.45      0.43      0.40      1715\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['KT'], 'score': [[[[437, 631], [207, 440]], [[868, 154], [537, 156]], [[1144, 196], [237, 138]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63      1172\n",
      "           1       0.11      0.10      0.11       334\n",
      "           2       0.15      0.24      0.18       209\n",
      "\n",
      "    accuracy                           0.46      1715\n",
      "   macro avg       0.31      0.32      0.31      1715\n",
      "weighted avg       0.49      0.46      0.48      1715\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['KT'], 'score': [[[[180, 363], [464, 708]], [[1106, 275], [299, 35]], [[1222, 284], [159, 50]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77      1401\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.48      0.15      0.23       310\n",
      "\n",
      "    accuracy                           0.64      1712\n",
      "   macro avg       0.43      0.30      0.33      1712\n",
      "weighted avg       0.74      0.64      0.67      1712\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['LT'], 'score': [[[[50, 261], [353, 1048]], [[1403, 308], [1, 0]], [[1353, 49], [264, 46]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.71      1229\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.55      0.11      0.18       483\n",
      "\n",
      "    accuracy                           0.55      1712\n",
      "   macro avg       0.41      0.28      0.30      1712\n",
      "weighted avg       0.65      0.55      0.56      1712\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['LT'], 'score': [[[[70, 413], [333, 896]], [[1404, 308], [0, 0]], [[1186, 43], [431, 52]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67      1192\n",
      "           1       0.01      0.07      0.01        27\n",
      "           2       0.39      0.08      0.13       493\n",
      "\n",
      "    accuracy                           0.51      1712\n",
      "   macro avg       0.34      0.28      0.27      1712\n",
      "weighted avg       0.56      0.51      0.50      1712\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['LT'], 'score': [[[[47, 473], [356, 836]], [[1379, 306], [25, 2]], [[1161, 58], [456, 37]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81      1521\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.19      0.10      0.13       179\n",
      "\n",
      "    accuracy                           0.68      1712\n",
      "   macro avg       0.35      0.28      0.31      1712\n",
      "weighted avg       0.80      0.68      0.73      1712\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['LT'], 'score': [[[[28, 163], [375, 1146]], [[1392, 308], [12, 0]], [[1456, 77], [161, 18]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.68      0.80      1627\n",
      "           1       0.01      0.13      0.02        38\n",
      "           2       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.66      1679\n",
      "   macro avg       0.32      0.27      0.27      1679\n",
      "weighted avg       0.93      0.66      0.77      1679\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['MT'], 'score': [[[[11, 41], [517, 1110]], [[1118, 523], [33, 5]], [[1665, 0], [14, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.79      1625\n",
      "           1       0.00      0.00      0.00        36\n",
      "           2       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.65      1679\n",
      "   macro avg       0.32      0.23      0.26      1679\n",
      "weighted avg       0.92      0.65      0.77      1679\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['MT'], 'score': [[[[2, 52], [526, 1099]], [[1115, 528], [36, 0]], [[1661, 0], [18, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.72      0.82      1506\n",
      "           1       0.16      0.63      0.26       134\n",
      "           2       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.70      1679\n",
      "   macro avg       0.37      0.45      0.36      1679\n",
      "weighted avg       0.86      0.70      0.75      1679\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['MT'], 'score': [[[[105, 68], [423, 1083]], [[1102, 443], [49, 85]], [[1640, 0], [39, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.81      1598\n",
      "           1       0.06      0.48      0.11        67\n",
      "           2       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.68      1679\n",
      "   macro avg       0.34      0.39      0.30      1679\n",
      "weighted avg       0.92      0.68      0.77      1679\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['MT'], 'score': [[[[37, 44], [491, 1107]], [[1116, 496], [35, 32]], [[1665, 0], [14, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75      1387\n",
      "           1       0.01      0.04      0.01        45\n",
      "           2       0.04      0.02      0.02       265\n",
      "\n",
      "    accuracy                           0.60      1697\n",
      "   macro avg       0.27      0.26      0.26      1697\n",
      "weighted avg       0.64      0.60      0.62      1697\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['NT'], 'score': [[[[14, 296], [382, 1005]], [[1400, 252], [43, 2]], [[1295, 137], [260, 5]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83      1605\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00        92\n",
      "\n",
      "    accuracy                           0.71      1697\n",
      "   macro avg       0.31      0.25      0.28      1697\n",
      "weighted avg       0.88      0.71      0.79      1697\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['NT'], 'score': [[[[0, 92], [396, 1209]], [[1443, 254], [0, 0]], [[1463, 142], [92, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.67      0.54       890\n",
      "           1       0.16      0.07      0.10       555\n",
      "           2       0.02      0.01      0.02       252\n",
      "\n",
      "    accuracy                           0.38      1697\n",
      "   macro avg       0.21      0.25      0.22      1697\n",
      "weighted avg       0.29      0.38      0.32      1697\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['NT'], 'score': [[[[101, 706], [295, 595]], [[928, 214], [515, 40]], [[1306, 139], [249, 3]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.73      1181\n",
      "           1       0.37      0.33      0.35       282\n",
      "           2       0.03      0.02      0.02       234\n",
      "\n",
      "    accuracy                           0.59      1697\n",
      "   macro avg       0.36      0.37      0.37      1697\n",
      "weighted avg       0.55      0.59      0.57      1697\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['NT'], 'score': [[[[117, 399], [279, 902]], [[1254, 161], [189, 93]], [[1325, 138], [230, 4]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66       844\n",
      "           1       0.70      0.04      0.07       850\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.51      1702\n",
      "   macro avg       0.40      0.34      0.25      1702\n",
      "weighted avg       0.60      0.51      0.36      1702\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['PT'], 'score': [[[[32, 826], [14, 830]], [[838, 14], [818, 32]], [[1694, 0], [8, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1669\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.95      1702\n",
      "   macro avg       0.33      0.32      0.33      1702\n",
      "weighted avg       0.96      0.95      0.96      1702\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['PT'], 'score': [[[[0, 33], [46, 1623]], [[1655, 46], [1, 0]], [[1670, 0], [32, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.99      0.43       466\n",
      "           1       0.87      0.03      0.06      1222\n",
      "           2       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.29      1702\n",
      "   macro avg       0.38      0.34      0.17      1702\n",
      "weighted avg       0.70      0.29      0.16      1702\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['PT'], 'score': [[[[40, 1196], [6, 460]], [[474, 6], [1182, 40]], [[1688, 0], [14, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.75      1021\n",
      "           1       0.43      0.03      0.06       644\n",
      "           2       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.60      1702\n",
      "   macro avg       0.35      0.34      0.27      1702\n",
      "weighted avg       0.53      0.60      0.47      1702\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['PT'], 'score': [[[[24, 657], [22, 999]], [[1032, 26], [624, 20]], [[1665, 0], [37, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      1586\n",
      "           1       0.09      0.21      0.13        43\n",
      "           2       0.00      0.00      0.00        81\n",
      "\n",
      "    accuracy                           0.83      1710\n",
      "   macro avg       0.34      0.37      0.35      1710\n",
      "weighted avg       0.86      0.83      0.85      1710\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['QT'], 'score': [[[[17, 107], [172, 1414]], [[1580, 87], [34, 9]], [[1536, 93], [81, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1703\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.89      1710\n",
      "   macro avg       0.33      0.30      0.31      1710\n",
      "weighted avg       0.99      0.89      0.94      1710\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['QT'], 'score': [[[[0, 7], [189, 1514]], [[1614, 96], [0, 0]], [[1610, 93], [7, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80      1236\n",
      "           1       0.30      0.10      0.15       287\n",
      "           2       0.00      0.00      0.00       187\n",
      "\n",
      "    accuracy                           0.66      1710\n",
      "   macro avg       0.34      0.33      0.32      1710\n",
      "weighted avg       0.57      0.66      0.60      1710\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['QT'], 'score': [[[[54, 420], [135, 1101]], [[1356, 67], [258, 29]], [[1430, 93], [187, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.85      1328\n",
      "           1       0.58      0.20      0.30       278\n",
      "           2       0.01      0.01      0.01       104\n",
      "\n",
      "    accuracy                           0.75      1710\n",
      "   macro avg       0.46      0.38      0.39      1710\n",
      "weighted avg       0.72      0.75      0.71      1710\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['QT'], 'score': [[[[78, 304], [111, 1217]], [[1392, 40], [222, 56]], [[1514, 92], [103, 1]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.69      1378\n",
      "           1       0.01      0.06      0.02        66\n",
      "           2       0.03      0.02      0.02       262\n",
      "\n",
      "    accuracy                           0.53      1706\n",
      "   macro avg       0.26      0.24      0.25      1706\n",
      "weighted avg       0.60      0.53      0.57      1706\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['RT'], 'score': [[[[18, 310], [480, 898]], [[1336, 304], [62, 4]], [[1259, 185], [257, 5]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71      1386\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.04      0.02      0.03       320\n",
      "\n",
      "    accuracy                           0.55      1706\n",
      "   macro avg       0.27      0.23      0.25      1706\n",
      "weighted avg       0.63      0.55      0.58      1706\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['RT'], 'score': [[[[36, 284], [462, 924]], [[1398, 308], [0, 0]], [[1203, 183], [313, 7]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70      1376\n",
      "           1       0.02      0.14      0.03        35\n",
      "           2       0.05      0.03      0.04       295\n",
      "\n",
      "    accuracy                           0.54      1706\n",
      "   macro avg       0.27      0.28      0.26      1706\n",
      "weighted avg       0.61      0.54      0.57      1706\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['RT'], 'score': [[[[28, 302], [470, 906]], [[1368, 303], [30, 5]], [[1230, 181], [286, 9]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69      1284\n",
      "           1       0.05      0.11      0.07       133\n",
      "           2       0.08      0.06      0.07       289\n",
      "\n",
      "    accuracy                           0.52      1706\n",
      "   macro avg       0.28      0.28      0.28      1706\n",
      "weighted avg       0.56      0.52      0.54      1706\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['RT'], 'score': [[[[78, 344], [420, 864]], [[1280, 293], [118, 15]], [[1243, 174], [273, 16]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71      1295\n",
      "           1       0.00      0.07      0.00        15\n",
      "           2       0.52      0.03      0.06       388\n",
      "\n",
      "    accuracy                           0.50      1698\n",
      "   macro avg       0.44      0.25      0.26      1698\n",
      "weighted avg       0.72      0.50      0.56      1698\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['ST'], 'score': [[[[179, 224], [458, 837]], [[1070, 613], [14, 1]], [[1299, 11], [376, 12]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.62      0.75      1662\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.60      1698\n",
      "   macro avg       0.32      0.21      0.25      1698\n",
      "weighted avg       0.95      0.60      0.74      1698\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['ST'], 'score': [[[[1, 35], [636, 1026]], [[1084, 614], [0, 0]], [[1639, 23], [36, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60       861\n",
      "           1       0.03      0.17      0.05       100\n",
      "           2       0.61      0.02      0.04       737\n",
      "\n",
      "    accuracy                           0.36      1698\n",
      "   macro avg       0.39      0.29      0.23      1698\n",
      "weighted avg       0.54      0.36      0.32      1698\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['ST'], 'score': [[[[353, 484], [284, 577]], [[1001, 597], [83, 17]], [[952, 9], [723, 14]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.64      0.74      1502\n",
      "           1       0.03      0.59      0.05        29\n",
      "           2       0.35      0.05      0.08       167\n",
      "\n",
      "    accuracy                           0.58      1698\n",
      "   macro avg       0.42      0.42      0.29      1698\n",
      "weighted avg       0.83      0.58      0.67      1698\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['ST'], 'score': [[[[89, 107], [548, 954]], [[1072, 597], [12, 17]], [[1516, 15], [159, 8]]]]}\n"
     ]
    }
   ],
   "source": [
    "strategy = {0:14000, 1:9000, 2:9000}\n",
    "\n",
    "machine_learning(emo_df,'Emotions',strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93      1697\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.87      1698\n",
      "   macro avg       0.33      0.29      0.31      1698\n",
      "weighted avg       1.00      0.87      0.93      1698\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['HT'], 'score': [[[[0, 1], [212, 1485]], [[1697, 0], [1, 0]], [[1486, 212], [0, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93      1698\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1698\n",
      "   macro avg       0.50      0.44      0.47      1698\n",
      "weighted avg       1.00      0.88      0.93      1698\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['HT'], 'score': [[[[0, 0], [212, 1486]], [[1486, 212], [0, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93      1698\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1698\n",
      "   macro avg       0.50      0.44      0.47      1698\n",
      "weighted avg       1.00      0.88      0.93      1698\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['HT'], 'score': [[[[0, 0], [212, 1486]], [[1486, 212], [0, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93      1698\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1698\n",
      "   macro avg       0.50      0.44      0.47      1698\n",
      "weighted avg       1.00      0.88      0.93      1698\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['HT'], 'score': [[[[0, 0], [212, 1486]], [[1486, 212], [0, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71      1379\n",
      "           1       0.19      0.26      0.22       256\n",
      "           2       0.00      0.00      0.00        92\n",
      "\n",
      "    accuracy                           0.55      1727\n",
      "   macro avg       0.32      0.30      0.31      1727\n",
      "weighted avg       0.66      0.55      0.60      1727\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['IT'], 'score': [[[[107, 241], [493, 886]], [[1176, 295], [189, 67]], [[1397, 238], [92, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79      1725\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.01      1.00      0.02         2\n",
      "\n",
      "    accuracy                           0.65      1727\n",
      "   macro avg       0.34      0.55      0.27      1727\n",
      "weighted avg       1.00      0.65      0.79      1727\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['IT'], 'score': [[[[2, 0], [598, 1127]], [[1365, 362], [0, 0]], [[1489, 236], [0, 2]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.77      1461\n",
      "           1       0.22      0.46      0.29       171\n",
      "           2       0.01      0.03      0.02        95\n",
      "\n",
      "    accuracy                           0.62      1727\n",
      "   macro avg       0.37      0.39      0.36      1727\n",
      "weighted avg       0.77      0.62      0.68      1727\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['IT'], 'score': [[[[134, 132], [466, 995]], [[1272, 284], [93, 78]], [[1397, 235], [92, 3]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.77      1444\n",
      "           1       0.28      0.39      0.33       259\n",
      "           2       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.63      1727\n",
      "   macro avg       0.39      0.36      0.37      1727\n",
      "weighted avg       0.78      0.63      0.69      1727\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['IT'], 'score': [[[[148, 135], [452, 992]], [[1208, 260], [157, 102]], [[1465, 238], [24, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68      1280\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.19      0.19      0.19       432\n",
      "\n",
      "    accuracy                           0.52      1712\n",
      "   macro avg       0.30      0.28      0.29      1712\n",
      "weighted avg       0.58      0.52      0.55      1712\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['JT'], 'score': [[[[111, 321], [463, 817]], [[1566, 146], [0, 0]], [[933, 347], [351, 81]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.61      0.66      1343\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.03      0.04      0.04       369\n",
      "\n",
      "    accuracy                           0.49      1712\n",
      "   macro avg       0.25      0.22      0.23      1712\n",
      "weighted avg       0.57      0.49      0.53      1712\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['JT'], 'score': [[[[50, 319], [524, 819]], [[1566, 146], [0, 0]], [[929, 414], [355, 14]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.64      0.48       679\n",
      "           1       0.63      0.15      0.24       621\n",
      "           2       0.14      0.15      0.14       412\n",
      "\n",
      "    accuracy                           0.34      1712\n",
      "   macro avg       0.38      0.31      0.29      1712\n",
      "weighted avg       0.41      0.34      0.31      1712\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['JT'], 'score': [[[[327, 706], [247, 432]], [[1037, 54], [529, 92]], [[932, 368], [352, 60]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1125\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.29      0.22      0.25       571\n",
      "\n",
      "    accuracy                           0.49      1712\n",
      "   macro avg       0.31      0.29      0.30      1712\n",
      "weighted avg       0.51      0.49      0.50      1712\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['JT'], 'score': [[[[170, 417], [404, 721]], [[1550, 146], [16, 0]], [[839, 302], [445, 126]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.50      0.45       846\n",
      "           1       0.42      0.15      0.22       869\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.32      1715\n",
      "   macro avg       0.27      0.22      0.22      1715\n",
      "weighted avg       0.41      0.32      0.33      1715\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['KT'], 'score': [[[[225, 644], [419, 427]], [[665, 181], [740, 129]], [[1381, 334], [0, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.52      0.53      1094\n",
      "           1       0.32      0.16      0.21       621\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39      1715\n",
      "   macro avg       0.28      0.23      0.25      1715\n",
      "weighted avg       0.46      0.39      0.41      1715\n",
      "\n",
      "{'metric': ['et_conf'], 'user': ['KT'], 'score': [[[[121, 500], [523, 571]], [[883, 211], [522, 99]], [[1381, 334], [0, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.53      0.50       944\n",
      "           1       0.36      0.15      0.21       771\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.36      1715\n",
      "   macro avg       0.28      0.23      0.24      1715\n",
      "weighted avg       0.42      0.36      0.37      1715\n",
      "\n",
      "{'metric': ['dt_conf'], 'user': ['KT'], 'score': [[[[204, 567], [440, 504]], [[746, 198], [659, 112]], [[1381, 334], [0, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.60      0.70      1527\n",
      "           1       0.09      0.14      0.11       188\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55      1715\n",
      "   macro avg       0.31      0.25      0.27      1715\n",
      "weighted avg       0.77      0.55      0.64      1715\n",
      "\n",
      "{'metric': ['xgb_conf'], 'user': ['KT'], 'score': [[[[27, 161], [617, 910]], [[1244, 283], [161, 27]], [[1381, 334], [0, 0]]]]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86      1706\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.76      1712\n",
      "   macro avg       0.33      0.25      0.29      1712\n",
      "weighted avg       0.99      0.76      0.86      1712\n",
      "\n",
      "{'metric': ['rf_conf'], 'user': ['LT'], 'score': [[[[0, 6], [403, 1303]], [[1404, 308], [0, 0]], [[1611, 95], [6, 0]]]]}\n"
     ]
    }
   ],
   "source": [
    "machine_learning(bio_df,'biometrics',strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning(df,'full-set',strategy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr,spearmanr\n",
    "\n",
    "ndf = df.drop(columns='user')\n",
    "pvals = pd.DataFrame([pearsonr(ndf[c], ndf['stress'])[1] for c in ndf.columns],\n",
    "                     index=ndf.columns)\n",
    "pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[[ 'Disgust','Scared','Surprised', \n",
    "       'eda_kurtosis','eda_skew', 'hr_std', 'hr_rms', 'hr_num_peaks', 'hr_amphitude',\n",
    "       'hr_duration', 'stress', 'user']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning(new_df,'Pearsons1',strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_bio = Pca(bio_df.drop(columns=['user','stress']),bio_df[['user','stress']])\n",
    "plot3d(pca_bio,(5,5),'bio')\n",
    "pca_emo = Pca(emo_df.drop(columns=['user','stress']),emo_df[['user','stress']])\n",
    "plot3d(pca_emo,(5,5),'emotion')\n",
    "full_pca = Pca(df.drop(columns=['user','stress']),df[['user','stress']])\n",
    "plot3d(full_pca,(5,5),'whole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = {0:14029, 1:7000, 2:7000}\n",
    "machine_learning(pca_bio.fillna(0),'PCA_bio',strategy)\n",
    "machine_learning(pca_emo.fillna(0),'PCA_emo',strategy)\n",
    "machine_learning(full_pca.fillna(0),'PCA_full',strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = {0:36000, 1:36000, 2:36000}\n",
    "print(pd.concat([pca_bio.drop(columns=['user','stress']),pca_emo]).stress.value_counts())\n",
    "machine_learning(pd.concat([pca_bio.drop(columns=['user','stress']),pca_emo]).fillna(0),'PCA_bio&PCA_emo',strategy)\n",
    "strategy = {0:36000, 1:7000, 2:7000}\n",
    "machine_learning(pd.concat([pca_bio.drop(columns=['user','stress']),emo_df]).fillna(0),'PCA_bio&emo',strategy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = {0:35034, 1:7000, 2:7000}\n",
    "machine_learning(pd.concat([pca_emo.drop(columns=['user','stress']),bio_df]).fillna(0),'bio&PCA_emo',strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = {0:12891, 1:12891, 2:12891}\n",
    "user = 'JT'\n",
    "dataframe = emo_df\n",
    "train_set = dataframe[dataframe['user'] != user]\n",
    "over = RandomOverSampler(sampling_strategy=strategy,random_state=42)\n",
    "su = SMOTE(random_state=42,sampling_strategy=strategy)\n",
    "#X_train, y_train = over.fit_resample(train_set.drop(columns= ['user','stress']), train_set['stress'])\n",
    "#under = RandomUnderSampler(sampling_strategy=strategy)\n",
    "X_train, y_train = su.fit_resample(train_set.drop(columns= ['user','stress']),train_set['stress'])\n",
    "\n",
    "test_set = dataframe[dataframe['user'] == user]\n",
    "print(test_set.stress.value_counts())\n",
    "print(np.unique(y_train,return_counts = True))\n",
    "rf = RandomForestClassifier(n_estimators = 100, max_depth=5, min_samples_leaf=5,random_state = 123)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(test_set.drop(columns=['user','stress']))\n",
    "print(multilabel_confusion_matrix(predictions,test_set['stress']))\n",
    "print('accuracy_score',accuracy_score(predictions,test_set['stress']))\n",
    "print('predictions',np.unique(predictions,return_counts=True))\n",
    "print(confusion_matrix(predictions,test_set['stress']))\n",
    "print('recall_score',recall_score(predictions,test_set['stress']),average = 'macro')\n",
    "print('f1_score',f1_score(predictions,test_set['stress']),average = 'macro')\n",
    "print('precision_score',precision_score(predictions,test_set['stress']),average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e6abdcc55c9525869dc29791932791dcdd58ba64bd8065ca093ed6eb1a0311d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
